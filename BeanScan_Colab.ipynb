{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BeanScan Defect Detection - Google Colab\n",
        "Fast training on GPU with your coffee defect dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install torchmetrics\n",
        "!pip install tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload your dataset\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Upload the Coffee Defect.v10i.coco.zip file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract dataset\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('dataset')\n",
        "        print(f'Extracted {filename} to dataset/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "    print('GPU Memory:', f\"{torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print('No GPU available - training will be slow')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the training script\n",
        "%%writefile train_colab.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.models.detection import fasterrcnn_mobilenet_v3_large_fpn, FasterRCNN_MobileNet_V3_Large_FPN_Weights\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import json\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchmetrics\n",
        "import random\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "class DefectDetectorFasterRCNN(nn.Module):\n",
        "    def __init__(self, num_classes: int, pretrained: bool = True, class_names: list = None):\n",
        "        super().__init__()\n",
        "        weights = FasterRCNN_MobileNet_V3_Large_FPN_Weights.COCO_V1 if pretrained else None\n",
        "        self.model = fasterrcnn_mobilenet_v3_large_fpn(weights=weights)\n",
        "        \n",
        "        # Replace the classifier with a new one for our number of classes\n",
        "        in_features = self.model.roi_heads.box_predictor.cls_score.in_features\n",
        "        self.model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "        \n",
        "        self.class_names = [\"__background__\"] + (class_names if class_names else [])\n",
        "        \n",
        "        if len(self.class_names) != num_classes:\n",
        "            raise ValueError(f\"class_names length ({len(self.class_names)}) must match num_classes ({num_classes})\")\n",
        "    \n",
        "    def forward(self, images, targets=None):\n",
        "        return self.model(images, targets)\n",
        "\n",
        "class BeanDefectDataset(Dataset):\n",
        "    def __init__(self, data_root, split='train', transforms=None):\n",
        "        self.data_root = data_root\n",
        "        self.split = split\n",
        "        self.transforms = transforms\n",
        "        \n",
        "        # Load annotations\n",
        "        ann_file = os.path.join(data_root, split, f'{split}_annotations.json')\n",
        "        with open(ann_file, 'r') as f:\n",
        "            self.annotations = json.load(f)\n",
        "        \n",
        "        # Get unique defect classes\n",
        "        defect_types = set()\n",
        "        for ann in self.annotations:\n",
        "            for defect in ann.get('defects', []):\n",
        "                defect_types.add(defect['type'])\n",
        "        \n",
        "        self.defect_classes = sorted(list(defect_types))\n",
        "        self.class_to_idx = {cls: idx + 1 for idx, cls in enumerate(self.defect_classes)}\n",
        "        \n",
        "        print(f\"Found {len(self.defect_classes)} defect classes: {self.defect_classes}\")\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        ann = self.annotations[idx]\n",
        "        \n",
        "        # Load image\n",
        "        img_path = os.path.join(self.data_root, self.split, 'images', ann['filename'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        \n",
        "        # Get targets\n",
        "        targets = []\n",
        "        labels = []\n",
        "        \n",
        "        for defect in ann.get('defects', []):\n",
        "            bbox = defect['bbox']  # [x, y, w, h]\n",
        "            x, y, w, h = bbox\n",
        "            \n",
        "            # Convert to [x1, y1, x2, y2] and clamp to image bounds\n",
        "            x1 = max(0, x)\n",
        "            y1 = max(0, y)\n",
        "            x2 = min(image.width, x + w)\n",
        "            y2 = min(image.height, y + h)\n",
        "            \n",
        "            # Skip invalid boxes\n",
        "            if x2 > x1 and y2 > y1 and (x2 - x1) > 1 and (y2 - y1) > 1:\n",
        "                targets.append([x1, y1, x2, y2])\n",
        "                labels.append(self.class_to_idx[defect['type']])\n",
        "        \n",
        "        # Convert to tensors\n",
        "        if targets:\n",
        "            targets = torch.tensor(targets, dtype=torch.float32)\n",
        "            labels = torch.tensor(labels, dtype=torch.int64)\n",
        "        else:\n",
        "            targets = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            labels = torch.zeros((0,), dtype=torch.int64)\n",
        "        \n",
        "        target_dict = {\n",
        "            'boxes': targets,\n",
        "            'labels': labels\n",
        "        }\n",
        "        \n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "        \n",
        "        return image, target_dict\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, targets = zip(*batch)\n",
        "    images = torch.stack(images, 0)\n",
        "    return images, list(targets)\n",
        "\n",
        "def train():\n",
        "    # Set seed for reproducibility\n",
        "    set_seed(42)\n",
        "    \n",
        "    # Setup\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Using device: {device}')\n",
        "    print(f'CUDA available: {torch.cuda.is_available()}')\n",
        "    if torch.cuda.is_available():\n",
        "        print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "        print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
        "    \n",
        "    # Data transforms\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
        "    ])\n",
        "    \n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    \n",
        "    # Load datasets\n",
        "    print(\"Loading datasets...\")\n",
        "    train_dataset = BeanDefectDataset('dataset', 'train', train_transforms)\n",
        "    val_dataset = BeanDefectDataset('dataset', 'val', val_transforms)\n",
        "    \n",
        "    print(f\"Train samples: {len(train_dataset)}\")\n",
        "    print(f\"Val samples: {len(val_dataset)}\")\n",
        "    \n",
        "    # Data loaders\n",
        "    batch_size = 8  # Good for Colab GPU\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=2)\n",
        "    \n",
        "    print(f\"Train batches: {len(train_loader)}\")\n",
        "    print(f\"Val batches: {len(val_loader)}\")\n",
        "    \n",
        "    # Model\n",
        "    num_classes = len(train_dataset.defect_classes) + 1  # +1 for background\n",
        "    model = DefectDetectorFasterRCNN(num_classes, pretrained=True, class_names=train_dataset.defect_classes)\n",
        "    model.to(device)\n",
        "    \n",
        "    print(f\"Model created with {num_classes} classes\")\n",
        "    print(f\"Defect classes: {train_dataset.defect_classes}\")\n",
        "    \n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "    \n",
        "    # Mixed precision scaler\n",
        "    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
        "    \n",
        "    # Training loop\n",
        "    num_epochs = 10\n",
        "    best_val_loss = float('inf')\n",
        "    \n",
        "    print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_batches = 0\n",
        "        \n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        print(\"-\" * 40)\n",
        "        \n",
        "        for batch_idx, (images, targets) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "            images = [img.to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            if scaler:\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    loss_dict = model(images, targets)\n",
        "                    losses = sum(loss for loss in loss_dict.values())\n",
        "                \n",
        "                scaler.scale(losses).backward()\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss_dict = model(images, targets)\n",
        "                losses = sum(loss for loss in loss_dict.values())\n",
        "                losses.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "            \n",
        "            train_loss += losses.item()\n",
        "            train_batches += 1\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_batches = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for images, targets in tqdm(val_loader, desc=\"Validation\"):\n",
        "                images = [img.to(device) for img in images]\n",
        "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "                \n",
        "                if scaler:\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        loss_dict = model(images, targets)\n",
        "                        losses = sum(loss for loss in loss_dict.values())\n",
        "                else:\n",
        "                    loss_dict = model(images, targets)\n",
        "                    losses = sum(loss for loss in loss_dict.values())\n",
        "                \n",
        "                val_loss += losses.item()\n",
        "                val_batches += 1\n",
        "        \n",
        "        avg_train_loss = train_loss / train_batches\n",
        "        avg_val_loss = val_loss / val_batches\n",
        "        \n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f}\")\n",
        "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "        \n",
        "        scheduler.step(avg_val_loss)\n",
        "        \n",
        "        # Save best model\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print(f\"âœ… New best model saved! Val Loss: {avg_val_loss:.4f}\")\n",
        "        else:\n",
        "            print(f\"Best val loss: {best_val_loss:.4f}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Training completed!\")\n",
        "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
        "    print(\"Model saved as 'best_model.pth'\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run training (this will take 30-60 minutes on Colab GPU)\n",
        "!python train_colab.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download trained model\n",
        "from google.colab import files\n",
        "files.download('best_model.pth')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
